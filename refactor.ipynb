{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31f8be3-a904-45fc-9c27-c665d50bca51",
   "metadata": {},
   "source": [
    "# An√°lise e Predi√ß√£o de Sele√ß√£o de Voos\n",
    "\n",
    "Este notebook aborda um problema cl√°ssico de **Sistema de Recomenda√ß√£o/Ranking** no contexto de sele√ß√£o de voos. Nosso objetivo √© prever qual voo um usu√°rio tem maior probabilidade de selecionar, dado um conjunto de op√ß√µes.\n",
    "\n",
    "---\n",
    "\n",
    "## Entendendo o Problema e o Objetivo\n",
    "\n",
    "Nosso desafio √© um problema de **aprendizado supervisionado** com foco em **ranking**, onde os dados s√£o estruturados em grupos (`ranker_id`).\n",
    "\n",
    "## M√©trica de Avalia√ß√£o: HitRate@3\n",
    "\n",
    "A performance do modelo ser√° avaliada usando o **HitRate@3**. Isso significa que acertaremos se o voo real (`selected = 1`) estiver entre os 3 primeiros voos classificados pelo nosso modelo, para cada grupo que contenha mais de 10 op√ß√µes de voo.\n",
    "\n",
    "## Configurando Op√ß√µes do Pandas\n",
    "\n",
    "Ajustamos as op√ß√µes de exibi√ß√£o do Pandas para facilitar a visualiza√ß√£o de DataFrames grandes, permitindo ver todas as colunas e um maior n√∫mero de linhas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e818c6b-6436-48ff-a5b3-de7839371ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- Split com GroupShuffleSplit\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# --- LightGBM Dataset\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ac1ef6-094e-4b16-bbe1-1b97481f37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetando as configura√ß√µes \n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "# setando as configura√ß√µes de coluna maxima\n",
    "# importante pois tem muitas colunas\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc862a0-a756-4ead-b8d1-83c57855a0fc",
   "metadata": {},
   "source": [
    "## 2. Download e extra√ß√£o dos dados\n",
    "Verifica se os arquivos da competi√ß√£o j√° est√£o dispon√≠veis localmente. Caso n√£o estejam:\n",
    "\n",
    "Faz o download via API do Kaggle.\n",
    "\n",
    "Extrai o conte√∫do na pasta data/aeroclub/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33d7fd1-d2de-4d9e-b223-12c08dea8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files():\n",
    "    # utilizando a API do kaggle para download\n",
    "    # adicionado a /data no git ignore\n",
    "    # Define caminhos\n",
    "    zip_path = \"data/aeroclub-recsys-2025.zip\"\n",
    "    extract_path = \"data/aeroclub\"\n",
    "    \n",
    "    # Cria a pasta base se necess√°rio\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    # Verifica se o arquivo .zip j√° foi baixado\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(\"üîΩ Baixando arquivos da competi√ß√£o...\")\n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"competitions\", \"download\",\n",
    "            \"-c\", \"aeroclub-recsys-2025\",\n",
    "            \"-p\", \"data\"\n",
    "        ])\n",
    "    else:\n",
    "        print(\"‚úÖ Arquivo ZIP j√° existe. Pulando download.\")\n",
    "\n",
    "    # Verifica se os arquivos j√° foram extra√≠dos\n",
    "    if not os.path.exists(extract_path) or not os.listdir(extract_path):\n",
    "        print(\"üì¶ Extraindo arquivos...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "    else:\n",
    "        print(\"‚úÖ Arquivos j√° extra√≠dos. Pulando extra√ß√£o.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2958ae-c6ea-47fc-884c-d67edd9483eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivo ZIP j√° existe. Pulando download.\n",
      "‚úÖ Arquivos j√° extra√≠dos. Pulando extra√ß√£o.\n"
     ]
    }
   ],
   "source": [
    "# Executa\n",
    "download_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bcffb-081b-42e2-87f7-6393d60b614b",
   "metadata": {},
   "source": [
    "## 3. Leitura dos dados\n",
    "Carrega o arquivo `train.parquet` utilizando a biblioteca Pandas. Este √© o conjunto de dados principal que ser√° usado para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ee0c7-6aa1-404d-9285-b3dd597542cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"data/aeroclub/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f501e65-1bde-465a-8095-01fe5b396d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36308db-3700-4225-9285-9c833ce76a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        \n",
    "        if col_type == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif col_type == 'object':\n",
    "            num_unique = df[col].nunique()\n",
    "            num_total = len(df[col])\n",
    "            if num_unique / num_total < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df\n",
    "train = reduce_memory_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de897686-07fa-4cbc-887b-d680cbbfa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd46f3-15fa-4932-93e8-135b0e52e7d6",
   "metadata": {},
   "source": [
    "## 4. Sele√ß√£o de colunas relevantes\n",
    "Filtra o DataFrame, mantendo apenas as colunas consideradas essenciais para o modelo de baseline. Isso inclui identificadores, informa√ß√µes do usu√°rio, detalhes do voo e rota, dados de precifica√ß√£o, regras de cancelamento/troca e a vari√°vel alvo (selected).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63def090-b4c1-4a4e-964e-7f6cfdbfea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as colunas que voc√™ quer manter\n",
    "columns_to_keep = [\n",
    "    # Identifiers\n",
    "    'Id',  # num\n",
    "    'ranker_id', \n",
    "    'profileId', \n",
    "    'companyID',\n",
    "    \n",
    "    # User info\n",
    "    'sex', 'nationality', 'frequentFlyer', 'isVip', 'bySelf', 'isAccess3D',\n",
    "\n",
    "    # Company info\n",
    "    'corporateTariffCode',\n",
    "\n",
    "    # Search & route\n",
    "    'searchRoute', 'requestDate',\n",
    "\n",
    "    # Pricing\n",
    "    'totalPrice', 'taxes',\n",
    "\n",
    "    # Flight timing\n",
    "    'legs0_departureAt', 'legs0_arrivalAt', 'legs0_duration',\n",
    "    'legs1_departureAt', 'legs1_arrivalAt', 'legs1_duration',\n",
    "\n",
    "    # Segment-level info (s√≥ do segmento 0 da ida para simplificar no baseline)\n",
    "    'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_marketingCarrier_code',\n",
    "    'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_aircraft_code',\n",
    "    'legs0_segments0_flightNumber',\n",
    "    'legs0_segments0_duration',\n",
    "    'legs0_segments0_baggageAllowance_quantity',\n",
    "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs0_segments0_cabinClass',\n",
    "    'legs0_segments0_seatsAvailable',\n",
    "\n",
    "    # Cancellation & exchange rules\n",
    "    'miniRules0_monetaryAmount', 'miniRules0_percentage', 'miniRules0_statusInfos',\n",
    "    'miniRules1_monetaryAmount', 'miniRules1_percentage', 'miniRules1_statusInfos',\n",
    "\n",
    "    # Pricing policy\n",
    "    'pricingInfo_isAccessTP', 'pricingInfo_passengerCount',\n",
    "\n",
    "    # Target\n",
    "    'selected'\n",
    "]\n",
    "\n",
    "# Filtra os dados para o baseline\n",
    "rows_to_copy = 1_000_000\n",
    "#rows_to_copy = len(df_train_raw)\n",
    "print(f\"rows to read: {rows_to_copy}\")\n",
    "df_train = df_train_raw[columns_to_keep].iloc[:rows_to_copy].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68857a98-3798-4c23-ae77-ae195801b902",
   "metadata": {},
   "source": [
    "### 5. Engenharia de features (corrige dtypes)\n",
    "Ajusta-se os tipos de dados de diversas colunas para garantir consist√™ncia e otimiza√ß√£o. Isso inclui a convers√£o de `nationality` para string, o tratamento de `frequentFlyer` para extra√ß√£o de programas de fidelidade, e a padroniza√ß√£o de colunas booleanas como `isVip` e `ricingInfo_isAccessTP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ce5ef-673e-4fdd-a7ee-075056c752c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fix_column_types(df):\n",
    "    df_fixed = df.copy()\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "            # Tenta converter para tipo num√©rico\n",
    "            try:\n",
    "                df_fixed[col] = pd.to_numeric(df[col])\n",
    "            except:\n",
    "                # Se n√£o for num√©rico, tenta bool\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                if set(unique_vals) <= {True, False}:\n",
    "                    df_fixed[col] = df[col].astype(bool)\n",
    "                else:\n",
    "                    df_fixed[col] = df[col].astype(str)\n",
    "    return df_fixed\n",
    "df_train = fix_column_types(df_train)\n",
    "\n",
    "# Ajusta a nacionalidade (est√° em Int)\n",
    "df_train[\"nationality\"] = df_train[\"nationality\"].astype(\"str\")\n",
    "\n",
    "\n",
    "df_train.dtypes  # Checar resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd9eb3-0645-483c-95f4-52c95ba551f3",
   "metadata": {},
   "source": [
    "## 5. Engenharia de features\n",
    "Nesta etapa, aprimora-se a representa√ß√£o dos dados de programas de milhagem:\n",
    "\n",
    "Calcula-se a quantidade de programas de milhagem associados a cada passageiro (`frequentFlyer_count`).\n",
    "\n",
    "Gera-se colunas booleanas individuais (`ff_...`) para cada companhia de milhagem, indicando se um passageiro possui cadastro naquele programa espec√≠fico.\n",
    "\n",
    "Cria-se uma flag bin√°ria (`hasFrequentFlyer`) para assinalar a presen√ßa de qualquer programa de milhagem.\n",
    "\n",
    "Remove-se a coluna original `frequentFlyer`, uma vez que suas informa√ß√µes foram transformadas em features mais granulares e utiliz√°veis pelo modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921672f-f88c-4855-86fe-c1a1449e0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequent_flyers(value):\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    return len(str(value).split('/'))\n",
    "\n",
    "df_train['frequentFlyer_count'] = df_train['frequentFlyer'].apply(count_frequent_flyers)\n",
    "\n",
    "# Cria flag bin√°ria para frequent flyer\n",
    "df_train['hasFrequentFlyer'] = df_train['frequentFlyer'].notnull().astype(int)\n",
    "\n",
    "# Substituir valores NaN por string vazia\n",
    "ff_series = df_train['frequentFlyer'].fillna('').astype(str)\n",
    "\n",
    "# Dividir por '/' para obter lista\n",
    "ff_lists = ff_series.str.split('/')\n",
    "\n",
    "all_programs = set(chain.from_iterable(ff_lists))\n",
    "print(f\"Total de companhias √∫nicas: {len(all_programs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2243a3b-c6c9-4cdf-bf62-8e44a9946097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('frequentFlyer', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d499e-6dfb-47f5-a6ba-ca75407f577d",
   "metadata": {},
   "source": [
    "## 5. Engenharia de features\n",
    "Converte colunas de data e hora para o formato adequado.\n",
    "\n",
    "Extrai a hora de partida, o dia da semana, a quantidade de dias at√© a viagem e a dura√ß√£o total da viagem.\n",
    "\n",
    "Adiciona flags bin√°rias para:\n",
    "\n",
    "`ida_fds` / `volta_fds`: Indica se a ida ou a volta ocorrem em um final de semana.\n",
    "\n",
    "`ida_comercial` / `volta_comercial`: Indica se a ida ou a volta ocorrem durante o hor√°rio comercial.\n",
    "\n",
    "Converte colunas de dura√ß√£o (que est√£o em formato de texto) para minutos, tornando-as num√©ricas e utiliz√°veis para an√°lise e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13fb0a-6db7-475e-ab4b-8bf5bd8d9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóìÔ∏è Colunas de datas e hor√°rios\n",
    "cols_datetime = [\n",
    "    'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt',\n",
    "    'legs1_departureAt', 'legs1_arrivalAt'\n",
    "]\n",
    "def process_datetime_and_duration(df):\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # Datas para datetime\n",
    "    for col in cols_datetime:\n",
    "        df_processed[col] = pd.to_datetime(df_processed[col], errors='coerce')\n",
    "\n",
    "    # Features de hora e dia da semana\n",
    "    df_processed['legs0_dep_hour'] = df_processed['legs0_departureAt'].dt.hour\n",
    "    df_processed['legs0_dep_dayofweek'] = df_processed['legs0_departureAt'].dt.dayofweek\n",
    "    df_processed['legs1_dep_hour'] = df_processed['legs1_departureAt'].dt.hour\n",
    "    df_processed['legs1_dep_dayofweek'] = df_processed['legs1_departureAt'].dt.dayofweek\n",
    "\n",
    "    # Dias entre ida e volta (dura√ß√£o da viagem)\n",
    "    df_processed['trip_days'] = (df_processed['legs1_departureAt'] - df_processed['legs0_departureAt']).dt.days\n",
    "\n",
    "    # Dias de anteced√™ncia (request ‚Üí ida)\n",
    "    df_processed['booking_to_trip_days'] = (df_processed['legs0_departureAt'] - df_processed['requestDate']).dt.days\n",
    "\n",
    "    # Final de semana (ida/volta)\n",
    "    df_processed['ida_fds'] = df_processed['legs0_dep_dayofweek'].isin([5, 6]).astype(int)\n",
    "    df_processed['volta_fds'] = df_processed['legs1_dep_dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Hor√°rio comercial (7h √†s 19h)\n",
    "    def is_business_hour(hour):\n",
    "        return int(7 <= hour <= 19)\n",
    "\n",
    "    df_processed['ida_comercial'] = df_processed['legs0_dep_hour'].apply(is_business_hour)\n",
    "    df_processed['volta_comercial'] = df_processed['legs1_dep_hour'].apply(is_business_hour)\n",
    "\n",
    "    # ‚è±Ô∏è Converter colunas de dura√ß√£o para minutos\n",
    "    def clean_and_convert_duration(col):\n",
    "        return (\n",
    "            col\n",
    "            .fillna(\"00:00:00\")\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(\"nan\", \"00:00:00\")\n",
    "            .pipe(pd.to_timedelta, errors='coerce')\n",
    "            .dt.total_seconds() / 60  # minutos\n",
    "        )\n",
    "\n",
    "    cols_duration = ['legs0_duration', 'legs1_duration']\n",
    "    for col in cols_duration:\n",
    "        df_processed[col] = clean_and_convert_duration(df_processed[col])\n",
    "\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbbbfc-0d31-4da9-89d9-944415d9a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['legs0_duration_minutes'] = (\n",
    "    pd.to_timedelta(\n",
    "        df_train['legs0_segments0_duration'].fillna(\"00:00:00\").astype(str).str.strip(),\n",
    "        errors='coerce'\n",
    "    ).dt.total_seconds() / 60  # em minutos\n",
    ")\n",
    "\n",
    "df_train.drop('legs0_segments0_duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b38f93-10e2-4af6-a911-957e0c470153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Applica√ß√£o\n",
    "df_train = process_datetime_and_duration(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94360c0-98d0-4875-a2b3-e1a1d46cb5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop(columns=cols_datetime, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f14d6b-048f-4df9-8da8-5011eb7b1abd",
   "metadata": {},
   "source": [
    "## 5. Engenharia de features\n",
    "booleans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e0c48-58a1-4ace-898d-96cec2d4adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = [\n",
    "    'pricingInfo_isAccessTP',\n",
    "    'hasFrequentFlyer',\n",
    "]\n",
    "\n",
    "for col in bool_cols:\n",
    "    df_train[col] = df_train[col].astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b92c1f-48ee-45c6-b260-557c6e54ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c1d77-7a61-4caf-827b-ba82772b63b8",
   "metadata": {},
   "source": [
    "## 8. Tratamento da Rota de Busca (searchRoute) üìç\n",
    "Garante que a coluna searchRoute, que descreve a rota da busca (ex: GRU-FOR, GRU-CGH-FOR), seja tratada como um tipo string. Isso padroniza a representa√ß√£o para an√°lises futuras ou para ser utilizada como uma feature categ√≥rica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ef241-fb6b-439d-b6a1-0e55c58e2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['searchRoute'] = df_train['searchRoute'].astype(str)\n",
    "df_train['searchRoute_count'] = df_train['searchRoute'].apply(lambda x: x.split(\"/\"))\n",
    "df_train['searchRoute_count'] = df_train['searchRoute_count'].apply(lambda x: len(x))\n",
    "print(f\" min {min(df_train['searchRoute_count'])}\")\n",
    "print(f\" max {max(df_train['searchRoute_count'])}\")\n",
    "df_train.drop('searchRoute_count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118a7d4-2852-4735-a93d-522c3c72dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garante que searchRoute est√° como string\n",
    "df_train['searchRoute'] = df_train['searchRoute'].astype(str)\n",
    "\n",
    "# Separa ida e volta\n",
    "df_train[['route_ida', 'route_volta']] = df_train['searchRoute'].str.split('/', expand=True)\n",
    "\n",
    "# Extrai origem e destino da ida\n",
    "df_train['ida_from'] = df_train['route_ida'].str[:3]\n",
    "df_train['ida_to'] = df_train['route_ida'].str[3:]\n",
    "\n",
    "# Extrai origem e destino da volta (se existir)\n",
    "df_train['volta_from'] = df_train['route_volta'].str[:3]\n",
    "df_train['volta_to'] = df_train['route_volta'].str[3:]\n",
    "\n",
    "df_train.drop('searchRoute', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586385f5-ca57-4b43-8511-b90778cd7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver todos os dtypes\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(df_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8a0d3-05e2-484d-a5b0-4628207cfe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target e grupo\n",
    "target_col = \"selected\"\n",
    "group_col = \"ranker_id\"\n",
    "\n",
    "# --- Categ√≥ricas para LightGBM\n",
    "categorical_cols = [\n",
    "    'nationality',\n",
    "    'legs0_segments0_departureFrom_airport_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_iata',\n",
    "    'legs0_segments0_arrivalTo_airport_city_iata',\n",
    "    'legs0_segments0_marketingCarrier_code',\n",
    "    'legs0_segments0_operatingCarrier_code',\n",
    "    'legs0_segments0_aircraft_code',\n",
    "    'corporateTariffCode',\n",
    "    \n",
    "    # novas features categ√≥ricas da searchRoute\n",
    "    'route_ida',\n",
    "    'route_volta',\n",
    "    'ida_from',\n",
    "    'ida_to',\n",
    "    'volta_from',\n",
    "    'volta_to'\n",
    "]\n",
    "\n",
    "# --- Booleanas e num√©ricas\n",
    "boolean_cols = [\n",
    "    'sex', 'isVip', 'bySelf', 'isAccess3D',\n",
    "    'pricingInfo_isAccessTP', 'hasFrequentFlyer',\n",
    "    'ida_fds', 'volta_fds',\n",
    "    'ida_comercial', 'volta_comercial'\n",
    "] + [col for col in df_train.columns if col.startswith(\"ff_\")]\n",
    "\n",
    "numeric_cols = [\n",
    "    'totalPrice', 'taxes',\n",
    "    'legs0_duration', 'legs1_duration',\n",
    "    'legs0_segments0_baggageAllowance_quantity',\n",
    "    'legs0_segments0_baggageAllowance_weightMeasurementType',\n",
    "    'legs0_segments0_cabinClass',\n",
    "    'legs0_segments0_seatsAvailable',\n",
    "    'miniRules0_monetaryAmount', 'miniRules0_percentage',\n",
    "    'miniRules1_monetaryAmount', 'miniRules1_percentage',\n",
    "    'booking_to_trip_days', 'trip_days',\n",
    "    'legs0_dep_hour', 'legs0_dep_dayofweek',\n",
    "    'legs1_dep_hour', 'legs1_dep_dayofweek',\n",
    "    'frequentFlyer_count', 'legs0_duration_minutes'\n",
    "]\n",
    "features = numeric_cols + categorical_cols + boolean_cols\n",
    "\n",
    "# --- Converte categ√≥ricas para category\n",
    "for col in categorical_cols:\n",
    "    df_train[col] = df_train[col].astype(\"category\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14470131-2fd4-47e1-ac22-ad73229e2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Separa√ß√£o por grupo (ranker_id)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df_train, groups=df_train[\"ranker_id\"]))\n",
    "\n",
    "df_train_split = df_train.iloc[train_idx].copy()\n",
    "df_val = df_train.iloc[val_idx].copy()\n",
    "\n",
    "# --- Features e targets\n",
    "X_train = df_train_split[features]\n",
    "y_train = df_train_split[target_col]\n",
    "groups_train = df_train_split[group_col].value_counts().sort_index().values\n",
    "\n",
    "X_val = df_val[features]\n",
    "y_val = df_val[target_col]\n",
    "groups_val = df_val[group_col].value_counts().sort_index().values\n",
    "\n",
    "# --- Par√¢metros que afetam o Dataset (incluindo GPU e max_bin!)\n",
    "dataset_params = {\n",
    "    \"max_bin\": 63,  # ou 31, se continuar com erro\n",
    "    \"device\": \"gpu\"\n",
    "}\n",
    "\n",
    "# --- Cria√ß√£o dos Datasets\n",
    "train_dataset = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    group=groups_train,\n",
    "    categorical_feature=categorical_cols,\n",
    "    params=dataset_params  # üí° AQUI √© onde max_bin deve ir tamb√©m!\n",
    ")\n",
    "\n",
    "val_dataset = lgb.Dataset(\n",
    "    X_val,\n",
    "    label=y_val,\n",
    "    group=groups_val,\n",
    "    categorical_feature=categorical_cols,\n",
    "    reference=train_dataset,\n",
    "    params=dataset_params\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9542f-45d9-4cf8-885f-2fefbd13f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm_model(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    boosting_type=\"gbdt\", \n",
    "    num_boost_round=1000, \n",
    "    early_stopping_rounds=50, \n",
    "    eval_log_every=50,\n",
    "    random_state=42\n",
    "):\n",
    "    print(f\"\\n--- Treinando modelo LightGBM com boosting: {boosting_type} ---\")\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",\n",
    "        \"ndcg_eval_at\": [3],\n",
    "        \"boosting_type\": boosting_type,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"min_data_in_leaf\": 20,\n",
    "        \"subsample\": 0.8,\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    # Par√¢metros adicionais para DART\n",
    "    if boosting_type == \"dart\":\n",
    "        params.update({\n",
    "            \"drop_rate\": 0.1,\n",
    "            \"skip_drop\": 0.5,\n",
    "        })\n",
    "        early_stopping = []  # n√£o funciona com DART\n",
    "        num_boost_round = max(num_boost_round, 1500)\n",
    "    else:\n",
    "        early_stopping = [lgb.early_stopping(early_stopping_rounds)]\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        valid_sets=[train_dataset, val_dataset],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        num_boost_round=num_boost_round,\n",
    "        callbacks=[\n",
    "            *early_stopping,\n",
    "            lgb.log_evaluation(eval_log_every)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_lgbm_model(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    boosting_type=\"dart\",     # ou \"gbdt\", \"goss\"\n",
    "    num_boost_round=2500,\n",
    "    early_stopping_rounds=100,\n",
    "    eval_log_every=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a3e1d-0ef4-4b2d-ad67-128a41516edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ‚úÖ Treinamento final com TODO o dataset de treino\n",
    "#     usando best_iteration encontrado na valida√ß√£o\n",
    "# ============================================================\n",
    "\n",
    "X_full = df_train[features]\n",
    "y_full = df_train[target_col]\n",
    "groups_full = df_train[group_col].value_counts().sort_index().values\n",
    "\n",
    "full_dataset = lgb.Dataset(X_full, y_full, group=groups_full, categorical_feature=categorical_cols)\n",
    "\n",
    "# ‚ö†Ô∏è Usa o n√∫mero ideal de itera√ß√µes do treino anterior\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    full_dataset,\n",
    "    num_boost_round=model.best_iteration  # << Aqui est√° a m√°gica\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fdf4a-6456-4043-a357-caa6e8c3a4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872670e0-ef39-4aad-8be6-d9989242ced0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42276c5b-db73-42bd-8b6e-440e29cb850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ## 6. Gera√ß√£o de Submiss√£o\n",
    "# ============================================================\n",
    "\n",
    "# 1. Ler test.parquet\n",
    "df_test = pd.read_parquet(\"data/aeroclub/test.parquet\")\n",
    "\n",
    "# 2. Aplicar transforma√ß√µes m√≠nimas necess√°rias\n",
    "df_test['ranker_id'] = df_test['ranker_id'].astype(str)\n",
    "df_test['nationality'] = df_test['nationality'].astype(str)\n",
    "df_test['searchRoute'] = df_test['searchRoute'].astype(str)\n",
    "\n",
    "# --- Frequent Flyer (mesmos one-hot do treino)\n",
    "df_test['frequentFlyer'] = df_test['frequentFlyer'].fillna('').astype(str)\n",
    "ff_lists_test = df_test['frequentFlyer'].str.split('/')\n",
    "\n",
    "for program in all_programs:\n",
    "    if program == '':\n",
    "        continue\n",
    "    df_test[f'ff_{program}'] = ff_lists_test.apply(lambda x: int(program in x))\n",
    "\n",
    "for col in [col for col in df_test.columns if col.startswith(\"ff_\")]:\n",
    "    df_test[col] = df_test[col].astype(pd.BooleanDtype())\n",
    "\n",
    "df_test['frequentFlyer_count'] = df_test['frequentFlyer'].apply(count_frequent_flyers)\n",
    "df_test['hasFrequentFlyer'] = df_test['frequentFlyer'].notnull().astype(int)\n",
    "df_test.drop(columns=['frequentFlyer'], inplace=True)\n",
    "\n",
    "# --- Datas\n",
    "cols_datetime = [\n",
    "    'requestDate',\n",
    "    'legs0_departureAt', 'legs0_arrivalAt',\n",
    "    'legs1_departureAt', 'legs1_arrivalAt'\n",
    "]\n",
    "for col in cols_datetime:\n",
    "    df_test[col] = pd.to_datetime(df_test[col], errors='coerce')\n",
    "\n",
    "df_test['legs0_dep_hour'] = df_test['legs0_departureAt'].dt.hour\n",
    "df_test['legs0_dep_dayofweek'] = df_test['legs0_departureAt'].dt.dayofweek\n",
    "df_test['legs1_dep_hour'] = df_test['legs1_departureAt'].dt.hour\n",
    "df_test['legs1_dep_dayofweek'] = df_test['legs1_departureAt'].dt.dayofweek\n",
    "df_test['trip_days'] = (df_test['legs1_departureAt'] - df_test['legs0_departureAt']).dt.days\n",
    "df_test['booking_to_trip_days'] = (df_test['legs0_departureAt'] - df_test['requestDate']).dt.days\n",
    "df_test['ida_fds'] = df_test['legs0_dep_dayofweek'].isin([5, 6]).astype(int)\n",
    "df_test['volta_fds'] = df_test['legs1_dep_dayofweek'].isin([5, 6]).astype(int)\n",
    "\n",
    "df_test['ida_comercial'] = df_test['legs0_dep_hour'].apply(lambda x: int(7 <= x <= 19))\n",
    "df_test['volta_comercial'] = df_test['legs1_dep_hour'].apply(lambda x: int(7 <= x <= 19))\n",
    "\n",
    "df_test.drop(columns=cols_datetime, inplace=True)\n",
    "\n",
    "# --- Dura√ß√£o\n",
    "def clean_and_convert_duration(col):\n",
    "    return (\n",
    "        col\n",
    "        .fillna(\"00:00:00\")\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(\"nan\", \"00:00:00\")\n",
    "        .pipe(pd.to_timedelta, errors='coerce')\n",
    "        .dt.total_seconds() / 60\n",
    "    )\n",
    "\n",
    "df_test['legs0_duration'] = clean_and_convert_duration(df_test['legs0_duration'])\n",
    "df_test['legs1_duration'] = clean_and_convert_duration(df_test['legs1_duration'])\n",
    "df_test['legs0_segments0_duration'] = clean_and_convert_duration(df_test['legs0_segments0_duration'])\n",
    "df_test['legs0_duration_minutes'] = df_test['legs0_duration']\n",
    "df_test.drop(columns=['legs0_segments0_duration'], inplace=True)\n",
    "\n",
    "# --- SearchRoute features\n",
    "df_test[['route_ida', 'route_volta']] = df_test['searchRoute'].str.split('/', expand=True)\n",
    "df_test['ida_from'] = df_test['route_ida'].str[:3]\n",
    "df_test['ida_to'] = df_test['route_ida'].str[3:]\n",
    "df_test['volta_from'] = df_test['route_volta'].str[:3]\n",
    "df_test['volta_to'] = df_test['route_volta'].str[3:]\n",
    "df_test.drop('searchRoute', axis=1, inplace=True)\n",
    "\n",
    "# --- Tipagem\n",
    "for col in categorical_cols:\n",
    "    df_test[col] = df_test[col].astype(\"category\")\n",
    "\n",
    "for col in boolean_cols:\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].astype('boolean')\n",
    "\n",
    "# 3. Prever com o modelo\n",
    "X_test = df_test[features]\n",
    "df_test['y_pred'] = model.predict(X_test)\n",
    "\n",
    "# 4. Gerar submiss√£o\n",
    "df_test_sorted = df_test.sort_values(['ranker_id', 'y_pred'], ascending=[True, False])\n",
    "df_test_sorted['selected'] = df_test_sorted.groupby('ranker_id').cumcount() + 1\n",
    "\n",
    "submission = df_test_sorted[['Id', 'ranker_id', 'selected']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ Arquivo de submiss√£o salvo como 'submission.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09d897-bf48-475b-ad77-ed5374fcd168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ef606-27d3-4e6a-b937-f24e1cf8d84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02987c5-818f-4ba9-91e8-070d6c4846cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a834c-3cd9-4396-ad09-0e96079158ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2051c5-cbe5-4f13-9a20-7932710eed92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FlightRec)",
   "language": "python",
   "name": "flightrec-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
